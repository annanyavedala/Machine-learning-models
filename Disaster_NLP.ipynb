{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster-NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnRqIQFeY84h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import tensorflow\n",
        "import keras\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j2C8LZ9ZV53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data= pd.read_csv('drive/My Drive/Kaggle Datasets/train (1).csv')\n",
        "test_data= pd.read_csv('drive/My Drive/Kaggle Datasets/test (1).csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f38fgt1IZtkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "47fa8e0d-cc65-496e-b31b-2fefb3ca20f4"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZiS6OLaXpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.drop(columns=['keyword', 'location', 'id'], inplace=True)\n",
        "test_data.drop(columns=['keyword', 'location'], inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayW061UZeiLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(name):\n",
        "    processed = name.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                     'emailaddress')\n",
        "\n",
        "    # Replace URLs with 'webaddress'\n",
        "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                      'webaddress')\n",
        "\n",
        "    # Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "\n",
        "    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                      'phonenumbr')\n",
        "\n",
        "    # Replace numbers with 'numbr'\n",
        "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
        "\n",
        "    # Remove punctuation\n",
        "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "    # Replace whitespace between terms with a single space\n",
        "    processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "    # Remove leading and trailing whitespace\n",
        "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
        "\n",
        "    # change words to lower case - Hello, HELLO, hello are all the same word\n",
        "    processed = processed.str.lower()\n",
        "    \n",
        "    return processed"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3bSicm3iX34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_train = clean_text(train_data[\"text\"])\n",
        "clean_test = clean_text(test_data[\"text\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzu_f_jnpJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "feb37a01-e51a-40c8-bb90-25c2dea85781"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "clean_train = clean_train.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))\n",
        "\n",
        "clean_test = clean_test.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBy6-fbzjIUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "clean_train= clean_train.apply(lambda x: \" \".join(ps.stem(word) for word in x.split() ))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twv5AW-LnVio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_test = clean_test.apply(lambda x:\" \".join([ps.stem(word) for word in x.split()]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA9KxZ37nY4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "21349f8e-d451-4b18-c4bd-677ebd015ca7"
      },
      "source": [
        "clean_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               deed reason earthquak may allah forgiv us\n",
              "1                    forest fire near la rong sask canada\n",
              "2       resid ask shelter place notifi offic evacu she...\n",
              "3       numbr numbr peopl receiv wildfir evacu order c...\n",
              "4       got sent photo rubi alaska smoke wildfir pour ...\n",
              "                              ...                        \n",
              "7608    two giant crane hold bridg collaps nearbi home...\n",
              "7609    aria_ahrari thetawniest control wild fire cali...\n",
              "7610    mnumbr numbr numbr utc numbrkm volcano hawaii ...\n",
              "7611    polic investig e bike collid car littl portug ...\n",
              "7612    latest home raze northern california wildfir a...\n",
              "Name: text, Length: 7613, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23WLED16nb12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15cde431-7392-490e-89f4-8a43c5db6df6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wl = WordNetLemmatizer()\n",
        "\n",
        "clean_train = clean_train.apply(lambda x:\" \".join([wl.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "clean_test = clean_test.apply(lambda x:\" \".join([wl.lemmatize(word) for word in x.split()]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwSnfSQwZSKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b4f3dc7b-11db-4a9b-96ab-823fa964701a"
      },
      "source": [
        "clean_test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                happen terribl car crash\n",
              "1           heard earthquak differ citi stay safe everyon\n",
              "2       forest fire spot pond gee flee across street c...\n",
              "3                          apocalyps light spokan wildfir\n",
              "4                typhoon soudelor kill numbr china taiwan\n",
              "                              ...                        \n",
              "3258      earthquak safeti lo angel ûò safeti fasten xrwn\n",
              "3259    storm ri wors last hurrican citi amp numbroth ...\n",
              "3260         green line derail chicago http co utbxlcbiuy\n",
              "3261    meg issu hazard weather outlook hwo http co nu...\n",
              "3262      cityofcalgari activ municip emerg plan yycstorm\n",
              "Name: text, Length: 3263, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA4DDFcGZaUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[\"text\"] = clean_train\n",
        "test_data[\"text\"] = clean_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqplRLaDZep5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 42\n",
        "\n",
        "X = train_data.text\n",
        "y = train_data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1CcZg3EZ9DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"Bernouli\", \"PassiveAggressiveClassifier\",\n",
        "     \"Naive Bayes\", \"SVC\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors=3),\n",
        "    DecisionTreeClassifier(random_state=0),\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    LogisticRegression(),\n",
        "    MultinomialNB(),\n",
        "    BernoulliNB(),\n",
        "    PassiveAggressiveClassifier(max_iter=50),\n",
        "    SVC(kernel=\"linear\")\n",
        "]\n",
        "\n",
        "zipped_clf = zip(names, classifiers)\n",
        "tvec = TfidfVectorizer()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO9jkrAtgxIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(pipeline, X_train, y_train, X_test, y_test):\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "   \n",
        "    print(\"-\"*30)\n",
        "    \n",
        "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    \n",
        "    print(\"-\"*30)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Lf5hUne4B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "def compare_clf(classifier=zipped_clf, vectorizer=tvec, n_features=10000, ngram_range=(1, 1)):\n",
        "    result = []\n",
        "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
        "    for n, c in classifier:\n",
        "        checker_pipeline = Pipeline([\n",
        "            (\"vectorizer\", vectorizer),\n",
        "            (\"classifier\", c)\n",
        "        ])\n",
        "        clf_acc = acc(checker_pipeline, X_train, y_train, X_test, y_test)\n",
        "        print(\"Model result for {}\".format(n))\n",
        "        print(c)\n",
        "        result.append((n, clf_acc))\n",
        "    return result"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4jz8TUQh3Kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb7913a2-756e-4d65-925e-caa888c48c80"
      },
      "source": [
        "trigram_result = compare_clf()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "accuracy score: 72.94%\n",
            "------------------------------\n",
            "Model result for Decision Tree\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=0, splitter='best')\n",
            "------------------------------\n",
            "accuracy score: 78.68%\n",
            "------------------------------\n",
            "Model result for Random Forest\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "------------------------------\n",
            "accuracy score: 80.69%\n",
            "------------------------------\n",
            "Model result for Logistic Regression\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "------------------------------\n",
            "accuracy score: 80.65%\n",
            "------------------------------\n",
            "Model result for Bernouli\n",
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "------------------------------\n",
            "accuracy score: 80.91%\n",
            "------------------------------\n",
            "Model result for PassiveAggressiveClassifier\n",
            "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "------------------------------\n",
            "accuracy score: 73.73%\n",
            "------------------------------\n",
            "Model result for Naive Bayes\n",
            "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
            "                            early_stopping=False, fit_intercept=True,\n",
            "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
            "                            n_jobs=None, random_state=None, shuffle=True,\n",
            "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "                            warm_start=False)\n",
            "------------------------------\n",
            "accuracy score: 79.77%\n",
            "------------------------------\n",
            "Model result for SVC\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10hMumaTiJl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(pipeline, testtext):\n",
        "    sentiment_fit = pipeline.fit(X_train,y_train)\n",
        "    y_pred = sentiment_fit.predict(testtext)\n",
        "    \n",
        "    return y_pred\n",
        "\n",
        "vectorizer=TfidfVectorizer()\n",
        "checker_pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', MultinomialNB())\n",
        "        ])\n",
        "vectorizer.set_params(stop_words=None, max_features=100000, ngram_range=(1,4))\n",
        "prediction=prediction(checker_pipeline,test_data['text'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atPlhJ9oiw3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c34e8284-811f-438c-a775-0a9e6816c8be"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WlzrpQXjLgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = test_data.id\n",
        "newFrame = pd.DataFrame({\"id\":index, \"target\":prediction})\n",
        "newFrame.to_csv(\"realnot.csv\", index=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05hSOeuyjNSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}